# -*- coding: utf-8 -*-
"""Logística .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fBlYIh__9Kwcs7HDDp-nbFazbmo3nf_v

Implementación de Regresión Logística
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from imblearn.over_sampling import SMOTE
import seaborn as sns



class RegresionLogisticaBinaria:
    def __init__(self, x, y, alpha=0.01, epochs=5000, lambda_reg=0.001, degree=1):
        self.degree = degree
        self.x = self.add_polynomial_features(np.insert(x, 0, 1, axis=1), degree)
        self.y = y - np.min(y)
        self.alpha = alpha
        self.epochs = epochs
        self.lambda_reg = lambda_reg
        self.num_features = self.x.shape[1]
        self.weights = np.random.randn(self.num_features) * 0.01
        self.losses = []

    def add_polynomial_features(self, X, degree):
        m, n = X.shape
        poly_features = [X]
        for d in range(2, degree + 1):
            for i in range(n):
                for j in range(i, n):
                    poly_features.append((X[:, i] * X[:, j]).reshape(-1, 1))
        return np.hstack(poly_features)

    def sigmoid(self, logits):
        """Función sigmoide"""
        return 1 / (1 + np.exp(-logits))

    def loss_function(self, logits, y_true):
        """Función de pérdida (cross-entropy) con regularización L2"""
        probabilities = self.sigmoid(logits)
        n = len(y_true)
        loss = -np.mean(y_true * np.log(probabilities + 1e-8) + (1 - y_true) * np.log(1 - probabilities + 1e-8))
        l2_reg = (self.lambda_reg / 2) * np.sum(self.weights ** 2)  # Regularización L2
        return loss + l2_reg

    def gradient(self, x, logits, y_true):
        """Cálculo del gradiente con L2"""
        probabilities = self.sigmoid(logits)
        n = len(y_true)
        gradient = np.dot(x.T, (probabilities - y_true)) / n
        gradient += self.lambda_reg * self.weights  # Regularización L2
        return gradient

    def train(self):
        """Entrenamiento del modelo"""
        for epoch in range(self.epochs):
            logits = np.dot(self.x, self.weights)  # Predicción (logits)
            loss = self.loss_function(logits, self.y)
            self.losses.append(loss)
#gradiente
            gradient = self.gradient(self.x, logits, self.y)
            self.weights -= self.alpha * gradient

            if epoch % 1000 == 0:  #100 epochs
                print(f"Época {epoch}/{self.epochs} - Pérdida: {loss:.5f}")

    def predict(self, x_test, threshold=0.5):
        """Predicción con el modelo entrenado"""
        x_test_bias = self.add_polynomial_features(np.insert(x_test, 0, 1, axis=1), self.degree)
        logits = np.dot(x_test_bias, self.weights)
        return (self.sigmoid(logits) >= threshold).astype(int)

    def predict_prob(self, x_test):
        """Predicción de probabilidades"""
        x_test_bias = self.add_polynomial_features(np.insert(x_test, 0, 1, axis=1), self.degree)
        logits = np.dot(x_test_bias, self.weights)
        return self.sigmoid(logits)

    def plot_loss(self):
        """Gráfico de la función de pérdida"""
        plt.plot(self.losses, label="Pérdida (entrenamiento)")
        plt.title("Evolución de la pérdida durante el entrenamiento")
        plt.xlabel("Épocas")
        plt.ylabel("Pérdida")
        plt.legend()
        plt.show()

"""Carga de Datos"""

df = pd.read_csv('/content/audio_features.csv')

X = df.drop(columns=['covid']).values
Y = df['covid'].values

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

"""Balanceo de data con SMOTE"""

smote = SMOTE(random_state=42) #seed para reproducibilidad
X_smote, Y_smote = smote.fit_resample(X_scaled, Y)

"""Conjuntos de entrenamiento y pruebas"""

X_train, X_test, y_train, y_test = train_test_split(X_smote, Y_smote, test_size=0.2, random_state=42)

modelo_rlb = RegresionLogisticaBinaria(X_train, y_train, alpha=0.01, epochs=5000, lambda_reg=0.001, degree=2)
modelo_rlb.train()


y_pred_prob_rlb = modelo_rlb.predict_prob(X_test)
best_threshold = 0.5
y_pred_rlb = (y_pred_prob_rlb >= best_threshold).astype(int)

cm_rlb = confusion_matrix(y_test, y_pred_rlb)
classification_rep_rlb = classification_report(y_test, y_pred_rlb)
accuracy_rlb = accuracy_score(y_test, y_pred_rlb)

print("Resultados de Regresión Logística")
print(f"Matriz de confusión con umbral {best_threshold}:")
print(cm_rlb)
print("\nReporte de clasificación:")
print(classification_rep_rlb)
print(f"Precisión del modelo: {accuracy_rlb * 100:.2f}%")

# Confussion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm_rlb, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title(f'Matriz de Confusión Regresión Logística con umbral {best_threshold}')
plt.xlabel('Predicción')
plt.ylabel('Clase Real')
plt.show()

plt.hist(y_pred_prob_rlb, bins=20, alpha=0.7, label='Predicciones Probabilísticas')
plt.axvline(x=best_threshold, color='red', linestyle='--', label=f'Umbral: {best_threshold}')
plt.title('Distribución de Probabilidades Predichas')
plt.xlabel('Probabilidad')
plt.ylabel('Frecuencia')
plt.legend()
plt.show()


modelo_rlb.plot_loss()

"""Comparación utilizando XGBCLASSIFFIER para el balanceo de DATA"""

import pandas as pd
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from xgboost import XGBClassifier
import matplotlib.pyplot as plt
import seaborn as sns


df = pd.read_csv('/content/audio_features.csv')

positive_samples = df[df['covid'] == 1]
negative_samples = df[df['covid'] == 0]

positive_samples_duplicated = positive_samples.sample(n=1057, replace=True, random_state=42)

df_balanced = pd.concat([negative_samples, positive_samples, positive_samples_duplicated]).reset_index(drop=True)

df_balanced = shuffle(df_balanced, random_state=42)

print("Balance de clases después de duplicar:")
print(df_balanced['covid'].value_counts())

X = df_balanced.drop(columns=['covid'])
Y = df_balanced['covid']

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

print('X_train:', X_train.shape)
print('X_test:', X_test.shape)

modelo_xgb = XGBClassifier(random_state=42, eval_metric='logloss')
modelo_xgb.fit(X_train, y_train)

y_pred = modelo_xgb.predict(X_test)

cm = confusion_matrix(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)
accuracy = accuracy_score(y_test, y_pred)



print("Matriz de confusión:")
print(cm)
print("\nReporte de clasificación:")
print(classification_rep)
print(f"Precisión del modelo: {accuracy * 100:.2f}%")

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
plt.title('Matriz de Confusión')
plt.xlabel('Predicción')
plt.ylabel('Clase Real')
plt.show()